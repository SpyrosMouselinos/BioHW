{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f786a078",
   "metadata": {},
   "source": [
    "# Learning a quadratic pseudo-metric from distance measurements\n",
    "\n",
    "Recall that pseudo-metric is a generalization of a metric space in which the distance between two distinct points can be zero.\n",
    "We are given a set of $N$ pairs of points in $\\mathbf{R}^n$, $x_1, \\ldots, x_N$, and $y_1, \\ldots, y_N$, together with a set of distances $d_1, \\ldots, d_N > 0$.\n",
    "  The goal is to find (or estimate or learn) a quadratic pseudo-metric $d$\n",
    "  $$d(x,y) =  \\left( (x-y)^T P(x-y) \\right)^{1/2},$$\n",
    "  $P\\in \\mathbf{S}^n_{+}$, which approximates the given distances, i.e., $d(x_i, y_i) \\approx d_i$. (The pseudo-metric $d$ is a metric only when $P \\succ 0$; when $P\\succeq 0$ is singular, it is a pseudo-metric.)\n",
    "  \n",
    "  To do this, we will choose $P\\in \\mathbf{S}^n_+$ that minimizes the mean squared error objective\n",
    "  \n",
    "  $$f(S)=\\frac{1}{N}\\sum_{i=1}^N (d_i - d(x_i,y_i))^2.$$\n",
    "  \n",
    "  ### Theoretical part.\n",
    "  1. Show that the objective function $f$ is convex (Hint: expand the square and see what happens.)\n",
    "  2. Show that the convex program $\\text{minimize }f(S)$, $S\\succeq 0$ can be expressed by an equivalent conic program with linear objective and a number of conic constraints using the $R^n_+$ (nonnegative orthant cone), $Q^n$ (second order cone), $Q_r^n$ (rotated second order cone), $S^n_+$ (positive semidefinite cone).\n",
    "  \n",
    "  ### Programming Part\n",
    "  1. Solve the program $\\text{minimize }f(S)$, $S\\succeq 0$, preferably using a modelling package like ``cvxpy``. Note that \"under the hood\" your modelling package translates the program to the conic form in point 2. above.\n",
    "  2. Use the obtained $P$ to measure the mean square error for the test data ``X_test``, ``Y_test``, ``d_test``.\n",
    "  \n",
    "---- \n",
    "*This exercise originates from \"Additional Exercises\" collection for Convex Optimization textbook of S. Boyd and L. Vandenberghe. Used under permission*"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Solution\n",
    "--------\n",
    "\n",
    "### Theoretical Part\n",
    "\n",
    "##### 1) Show that the objective function $f$ is convex - Note: The exersize says $f(S)$ but since our variable is P, I think it makes sense to refer to it as $f(P)$ instead\n",
    "\n",
    "To show that the objective function $\\( f(P) \\)$ is convex, we first expand the expression for $\\( d(x_i, y_i) \\)$:\n",
    "$d(x_i, y_i) = (x_i - y_i)^T P (x_i - y_i) ^{1/2}.$\n",
    "\n",
    "Substitute this into the objective function $\\( f(P) \\)$:\n",
    "$f(P) = \\frac{1}{N} \\sum_{i=1}^N ( d_i - \\left( (x_i - y_i)^T P (x_i - y_i) \\right)^{1/2})^2.$\n",
    "\n",
    "Let $\\( z_i = x_i - y_i \\)$. Then, the objective function becomes:\n",
    "$f(P) = \\frac{1}{N} \\sum_{i=1}^N (d_i - \\left( z_i^T P z_i \\right)^{1/2})^2.$\n",
    "\n",
    "To prove convexity, we need to show that $\\( f(P) \\)$ is a convex function of $\\( P \\)$. By expanding the square we end up:\n",
    "$f(P) = \\frac{1}{N} \\sum_{i=1}^N ( d_i^2 - 2 d_i (z_i^T P z_i)^{1/2} + z_i^T P z_i).$\n",
    "\n",
    "We can ignore the $\\frac{1}{N}$ for our analysis, end we end up with a sum of terms that look like:\n",
    "\n",
    "$d_i^2 - 2 d_i (z_i^T P z_i)^{1/2} + z_i^T P z_i$\n",
    "\n",
    "For each term:\n",
    "- $\\( d_i^2 \\)$ is constant with respect to \\( P \\).\n",
    "- $\\( z_i^T P z_i \\)$ is linear in $\\( P \\)$ because $\\( P \\in \\mathbf{S}^n_+ \\)$, and the product $\\( z_i^T P z_i \\)$ is a linear function of $\\( P \\)$.\n",
    "- The square root of the affine function $z_i^T P z_i$ is concave and multiplying by a negative constant $-2 d_i$ makes it convex. $-2 d_i (z_i^T P z_i)^{1/2}$ is convex.\n",
    "\n",
    "Therefore, each term of the summation is a sum of a constant, a linear term, and a convex term, thus a convex term. The sum of convex terms is convex, which makes $\\( f(P) \\)$ a convex function.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Theoretical Part\n",
    "\n",
    "##### 2) Show that the convex program can be expressed by an equivalent conic program with linear objective and a number of conic constraints using the $R^n_+$ (nonnegative orthant cone), $Q^n$ (second order cone), $Q_r^n$ (rotated second order cone), $S^n_+$ (positive semidefinite cone).\n",
    "\n",
    "#### Conversion to conic problem with linear objective\n",
    "\n",
    "We can start by defining  $t_i$ to represent $\\sqrt{((x_i - y_i)^T P (x_i - y_i))}$:\n",
    "\n",
    "- $t_i = \\sqrt{(x_i - y_i)^T P (x_i - y_i)}$\n",
    "\n",
    "Then we can rewrite the objective function using slack variables $t_i$ and $u_i$ to represent $\\((d_i - t_i)^2\\)$:\n",
    "- $u_i = (d_i - t_i)^2 $\n",
    "\n",
    "Our goal is to minimize:\n",
    "$f(u) = \\frac{1}{N} \\sum_{i=1}^N u_i.$ or the equivalent $f(u) = \\sum_{i=1}^N u_i.$ or even $f(u) = \\quad 1^T \\mathbf{u}.$ with $\\mathbf{u}$ a N-dimensional vector with N the size of the datapoints.\n",
    "\n",
    "#### Constraints\n",
    "\n",
    "1. **Second-Order Cone (SOC) Constraint for $t_i$**:\n",
    "   $$ t_i^2 \\geq (x_i - y_i)^T P (x_i - y_i), \\quad \\forall i $$\n",
    "   $$\n",
    "   \\| \\begin{pmatrix} t_i \\\\ (x_i - y_i)^T P^{1/2} \\end{pmatrix}\\|_2 \\leq t_i\n",
    "   $$\n",
    "   $$\n",
    "   (t_i, (x_i - y_i)^T P (x_i - y_i)) \\in Q^n\n",
    "   $$\n",
    "   where\n",
    "   $$\n",
    "   Q^n = \\{(t, x) \\mid \\|x\\|_2^2 \\leq t\\}\n",
    "   $$\n",
    "\n",
    "\n",
    "2. **Rotated Second-Order Cone (RSOC) Constraint for $u_i$**:\n",
    "   We can express $\\( (d_i - t_i)^2 \\leq u_i \\)$:\n",
    "   $$\n",
    "   \\| \\begin{pmatrix} 2\\sqrt{u_i} \\\\ d_i - t_i \\end{pmatrix} \\|_2 \\leq d_i + t_i, \\quad \\forall i\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   (u_i, 1, d_i - t_i) \\in Q_r^n\n",
    "   $$\n",
    "   where\n",
    "   $$\n",
    "   Q_r^n = \\{(u, v, w) \\mid 2uv \\geq w^2, u \\geq 0, v \\geq 0 \\}\n",
    "   $$\n",
    "\n",
    "3. **Positive Semidefinite Cone (PSD) Constraint**:\n",
    "   $$ P \\succeq 0 $$ or $$P \\in S^n_+$$\n",
    "\n",
    "4. **Non-Negativity Constraint**:\n",
    "   $$ u_i \\geq 0, \\quad t_i \\geq 0, \\quad \\forall i $$ or $$u_i, t_i \\in R^n_+$$\n",
    "\n",
    "The final conic program is:\n",
    "\n",
    "$$\n",
    "\\text{minimize} \\quad 1^T \\mathbf{u}\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "| \\begin{pmatrix} t_i \\\\ (x_i - y_i)^T P^{1/2} \\end{pmatrix} \\|_2 \\leq t_i, \\quad \\forall i \\quad \\text{(SOC)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\| \\begin{pmatrix} 2\\sqrt{u_i} \\\\ d_i - t_i \\end{pmatrix} \\|_2 \\leq d_i + t_i, \\quad \\forall i \\quad \\text{(RSOC)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P \\in S^n_+\n",
    "$$\n",
    "\n",
    "$$\n",
    "u_i \\in R^n_+, t_i \\in R^n_+, \\forall i \\quad \\text{(Non-Negativity)}\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf8da0bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:22:46.330034100Z",
     "start_time": "2024-05-17T11:22:46.321517300Z"
    }
   },
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from scipy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0d2b41f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:48:02.944704200Z",
     "start_time": "2024-05-17T11:48:02.927061500Z"
    }
   },
   "outputs": [],
   "source": [
    "# In this box we generate the input data\n",
    "\n",
    "np.random.seed(5680)\n",
    "\n",
    "n = 5 # Dimension\n",
    "N = 100 # Number of samples\n",
    "\n",
    "P = np.random.randn(n,n)\n",
    "P = P.dot(P.T) + np.identity(n)\n",
    "sqrtP = la.sqrtm(P)\n",
    "\n",
    "x = np.random.randn(N,n)\n",
    "y = np.random.randn(N,n)\n",
    "\n",
    "d = np.linalg.norm(sqrtP.dot((x-y).T),axis=0)    # distances according to metric P\n",
    "d = np.maximum(d+np.random.randn(N),0)           # add random noise\n",
    "\n",
    "N_test = 10 # Samples for test set\n",
    "X_test = np.random.randn(N_test,n)\n",
    "Y_test = np.random.randn(N_test,n)\n",
    "d_test = np.linalg.norm(sqrtP.dot((X_test-Y_test).T),axis=0)  # distances according to metric P\n",
    "d_test = np.maximum(d_test+np.random.randn(N_test),0)         # add random noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### My solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error is 0.720322118721639\n"
     ]
    }
   ],
   "source": [
    "### Training ###\n",
    "P_approx = cp.Variable((n, n), PSD=True) # Let's setup our approximation of P matrix\n",
    "objective = 0 # Let's initialize our objective\n",
    "# Adding all terms of the form d_i**2\n",
    "for distance in d:\n",
    "    objective += distance**2\n",
    "# Adding all terms of the form - 2d_i (x_i - y_i)^T P (x_i - y_i))^{1/2}\n",
    "for distance, x_i, y_i in zip(d, x, y):\n",
    "    objective += -2*distance*cp.sqrt(cp.quad_form((x_i - y_i),P_approx))\n",
    "# Adding all terms of the form  (x_i - y_i)^T P (x_i - y_i))\n",
    "for x_i, y_i in zip(x, y):\n",
    "    objective += cp.quad_form((x_i - y_i),P_approx)\n",
    "\n",
    "problem = cp.Problem(cp.Minimize(objective / N))\n",
    "tre = problem.solve()\n",
    "print(f\"Training Error is {tre}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T11:48:12.221447600Z",
     "start_time": "2024-05-17T11:48:11.748443500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error is 0.9157737162514736\n"
     ]
    }
   ],
   "source": [
    "### Testing ###\n",
    "d_guessed = np.linalg.norm(la.sqrtm(P_approx.value).dot((X_test-Y_test).T),axis=0)\n",
    "tse = (np.linalg.norm(d_test - d_guessed)**2)/N_test\n",
    "print(f\"Test Error is {tse}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T11:48:24.496741900Z",
     "start_time": "2024-05-17T11:48:24.481061500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
